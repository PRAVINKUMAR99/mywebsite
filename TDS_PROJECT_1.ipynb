{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "\n",
        "api_token='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'\n",
        "\n",
        "# GitHub API URL\n",
        "base_url = 'https://api.github.com'\n",
        "headers = {'Authorization': f'token {api_token}'}\n",
        "\n",
        "users_data=[]\n",
        "page = 1\n",
        "while True:\n",
        "    users_url = f\"{base_url}/search/users?q=location:Tokyo+followers:>=200&page={page}&per_page=100\"\n",
        "    response = requests.get(users_url, headers=headers)\n",
        "    data = response.json()\n",
        "    if 'items' not in data or not data['items']:\n",
        "        break\n",
        "    users_data.extend(data['items'])\n",
        "    page += 1\n",
        "\n",
        "# Extract user info\n",
        "users = []\n",
        "for user in users_data:\n",
        "    user_detail_url = user['url']\n",
        "    user_response = requests.get(user_detail_url, headers=headers)\n",
        "    user_info = user_response.json()\n",
        "\n",
        "    # Clean up company name\n",
        "    company = user_info.get('company', '')\n",
        "    if company:\n",
        "        company = company.strip().lstrip('@').upper()\n",
        "\n",
        "    users.append({\n",
        "        'login': user_info['login'],\n",
        "        'name': user_info['name'],\n",
        "        'company': company,\n",
        "        'location': user_info['location'],\n",
        "        'email': user_info['email'],\n",
        "        # 'hireable': user_info['hireable'] if user_info['hireable'] else False,\n",
        "        'hireable': 'true' if user_info['hireable'] else 'false',\n",
        "        'bio': user_info['bio'],\n",
        "        'public_repos': user_info['public_repos'],\n",
        "        'followers': user_info['followers'],\n",
        "        'following': user_info['following'],\n",
        "        'created_at': user_info['created_at']\n",
        "        })\n",
        "\n",
        "# Convert to DataFrame and save as CSV\n",
        "users_df = pd.DataFrame(users)\n",
        "users_df.to_csv('users.csv', index=False)\n",
        "\n",
        "# Fetch repositories for each user\n",
        "repos = []\n",
        "for user in users:\n",
        "    page = 1\n",
        "    user_repos=[]\n",
        "    while True:\n",
        "        repos_url = f\"{base_url}/users/{user['login']}/repos?sort=pushed&direction=desc&page={page}&per_page=100\"\n",
        "        # repos_url = f\"{base_url}/users/{user['login']}/repos?per_page=100\"\n",
        "        repos_response = requests.get(repos_url, headers=headers)\n",
        "        repos_data = repos_response.json()\n",
        "        if not repos_data or len(user_repos) >= 500:\n",
        "            break\n",
        "        for repo in repos_data:\n",
        "            if len(user_repos) >= 500:\n",
        "                break\n",
        "        # for repo in repos_data:\n",
        "            user_repos.append({\n",
        "                'login': user['login'],\n",
        "                'full_name': repo['full_name'],\n",
        "                'created_at': repo['created_at'],\n",
        "                'stargazers_count': repo['stargazers_count'],\n",
        "                'watchers_count': repo['watchers_count'],\n",
        "                'language': repo['language'],\n",
        "                'has_projects': 'true' if repo['has_projects'] else 'false',\n",
        "                'has_wiki': 'true' if repo['has_wiki'] else 'false',\n",
        "                'license_name': repo['license']['name'] if repo['license'] else None\n",
        "            })\n",
        "        page+=1\n",
        "    repos.extend(user_repos)\n",
        "\n",
        "# Convert to DataFrame and save as CSV\n",
        "repos_df = pd.DataFrame(repos)\n",
        "repos_df.to_csv('repositories.csv', index=False)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Data scraping and file creation completed.\")\n",
        "users_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "CeWagpP3hTkp",
        "outputId": "63528afd-ebcd-4e96-916d-98bccb9b2380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0a7c10449184>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0musers_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0muser_detail_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0muser_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_detail_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0muser_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    790\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from datetime import datetime\n",
        "\n",
        "# Load users from CSV and filter by Tokyo location\n",
        "def load_users(file_path):\n",
        "    users = []\n",
        "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "        csv_reader = csv.DictReader(file)\n",
        "        for row in csv_reader:\n",
        "            # Check if the user is located in Tokyo (case insensitive)\n",
        "            if row[\"location\"].strip().lower() == \"tokyo\":\n",
        "                # Append user info along with parsed created_at date\n",
        "                users.append({\n",
        "                    \"login\": row[\"login\"],\n",
        "                    \"created_at\": datetime.strptime(row[\"created_at\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
        "                })\n",
        "    return users\n",
        "\n",
        "def find_earliest_users(users, top_n=5):\n",
        "    # Sort users by the created_at date\n",
        "    sorted_users = sorted(users, key=lambda x: x[\"created_at\"])\n",
        "    # Get the logins of the top N earliest users\n",
        "    earliest_users = [user[\"login\"] for user in sorted_users[:top_n]]\n",
        "    return \", \".join(earliest_users)\n",
        "\n",
        "# Main execution\n",
        "users = load_users(\"users.csv\")\n",
        "earliest_users_logins = find_earliest_users(users)\n",
        "print(\"Earliest registered users in Tokyo:\", earliest_users_logins)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHC5W7_tv-Is",
        "outputId": "a6cbcfd7-82be-493d-e715-ff6b901005f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Earliest registered users in Tokyo: mootoh, lhl, proppy, takuma104, javascripter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from collections import Counter\n",
        "\n",
        "def load_and_count_companies(file_path):\n",
        "    companies = []\n",
        "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "        csv_reader = csv.DictReader(file)\n",
        "        for row in csv_reader:\n",
        "            # Check if the user is located in Tokyo (case insensitive)\n",
        "            if row[\"location\"].strip().lower() == \"tokyo\":\n",
        "                # Standardize the company names\n",
        "                company = row[\"company\"].strip().upper() if row[\"company\"] else \"UNKNOWN\"\n",
        "                companies.append(company)\n",
        "\n",
        "    # Count occurrences of each company\n",
        "    company_counts = Counter(companies)\n",
        "    # Get the company with the most users\n",
        "    majority_company = company_counts.most_common(1)\n",
        "    return majority_company[0][0] if majority_company else \"UNKNOWN\"\n",
        "\n",
        "# Main execution\n",
        "majority_company = load_and_count_companies(\"users.csv\")\n",
        "print(\"The company with the most developers in Tokyo is:\", majority_company)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb5HR1a65xmI",
        "outputId": "7b13f9cc-6db2-4a1e-b6f4-fb41018ce95d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The company with the most developers in Tokyo is: UNKNOWN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "\n",
        "def load_users_joined_after_2020(file_path):\n",
        "    users = set()\n",
        "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "        csv_reader = csv.DictReader(file)\n",
        "        for row in csv_reader:\n",
        "            # Check if user joined after 2020\n",
        "            created_at = datetime.strptime(row[\"created_at\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
        "            if created_at.year > 2020:\n",
        "                users.add(row[\"login\"])\n",
        "    return users\n",
        "\n",
        "def count_languages_for_users(users, file_path):\n",
        "    languages = []\n",
        "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "        csv_reader = csv.DictReader(file)\n",
        "        for row in csv_reader:\n",
        "            # Only consider repositories of users who joined after 2020\n",
        "            if row[\"login\"] in users:\n",
        "                language = row[\"language\"].strip() if row[\"language\"] else \"Unknown\"\n",
        "                languages.append(language)\n",
        "\n",
        "    # Count occurrences of each language\n",
        "    language_counts = Counter(languages)\n",
        "    return language_counts\n",
        "\n",
        "def find_second_most_popular_language(language_counts):\n",
        "    # Get the two most common languages\n",
        "    most_common_languages = language_counts.most_common(2)\n",
        "    return most_common_languages[1][0] if len(most_common_languages) > 1 else \"Unknown\"\n",
        "\n",
        "# Main execution\n",
        "users_after_2020 = load_users_joined_after_2020(\"users.csv\")\n",
        "language_counts = count_languages_for_users(users_after_2020, \"repositories.csv\")\n",
        "second_most_popular_language = find_second_most_popular_language(language_counts)\n",
        "\n",
        "print(\"The second most popular programming language among users who joined after 2020 is:\", second_most_popular_language)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6doZCjr-7jwi",
        "outputId": "47e1f877-0eec-4ede-94d9-30f119ff628b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The second most popular programming language among users who joined after 2020 is: TypeScript\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "\n",
        "def count_languages_in_recent_repositories(file_path):\n",
        "    languages = []\n",
        "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "        csv_reader = csv.DictReader(file)\n",
        "        for row in csv_reader:\n",
        "            # Check if the repository was created after 2020\n",
        "            created_at = datetime.strptime(row[\"created_at\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
        "            if created_at.year > 2020:\n",
        "                language = row[\"language\"].strip() if row[\"language\"] else \"Unknown\"\n",
        "                languages.append(language)\n",
        "\n",
        "    # Count occurrences of each language\n",
        "    language_counts = Counter(languages)\n",
        "    return language_counts\n",
        "\n",
        "def find_second_most_popular_language(language_counts):\n",
        "    # Get the two most common languages\n",
        "    most_common_languages = language_counts.most_common(2)\n",
        "    return most_common_languages[1][0] if len(most_common_languages) > 1 else \"Unknown\"\n",
        "\n",
        "# Main execution\n",
        "language_counts = count_languages_in_recent_repositories(\"repositories.csv\")\n",
        "second_most_popular_language = find_second_most_popular_language(language_counts)\n",
        "\n",
        "print(\"The second most popular programming language among repositories created after 2020 is:\", second_most_popular_language)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfc6Q4qy75Q7",
        "outputId": "5c96d4cf-0ad3-490d-f1f0-0582f68cf3fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The second most popular programming language among repositories created after 2020 is: TypeScript\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from collections import Counter\n",
        "\n",
        "def analyze_projects_and_wikis(file_path):\n",
        "    # Counters for different combinations of projects and wiki\n",
        "    project_and_wiki = 0\n",
        "    only_project = 0\n",
        "    only_wiki = 0\n",
        "    neither = 0\n",
        "\n",
        "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "        csv_reader = csv.DictReader(file)\n",
        "        for row in csv_reader:\n",
        "            has_projects = row[\"has_projects\"].strip().lower() == \"true\"\n",
        "            has_wiki = row[\"has_wiki\"].strip().lower() == \"true\"\n",
        "\n",
        "            if has_projects and has_wiki:\n",
        "                project_and_wiki += 1\n",
        "            elif has_projects:\n",
        "                only_project += 1\n",
        "            elif has_wiki:\n",
        "                only_wiki += 1\n",
        "            else:\n",
        "                neither += 1\n",
        "\n",
        "    # Calculate total counts\n",
        "    total_repos = project_and_wiki + only_project + only_wiki + neither\n",
        "\n",
        "    # Calculate correlation values\n",
        "    correlation_data = {\n",
        "        \"both\": project_and_wiki,\n",
        "        \"only_projects\": only_project,\n",
        "        \"only_wiki\": only_wiki,\n",
        "        \"neither\": neither,\n",
        "        \"total_repos\": total_repos\n",
        "    }\n",
        "\n",
        "    return correlation_data\n",
        "\n",
        "# Main execution\n",
        "correlation_results = analyze_projects_and_wikis(\"repositories.csv\")\n",
        "\n",
        "print(\"Correlation Analysis of Projects and Wikis:\")\n",
        "print(f\"Repositories with both projects and wikis: {correlation_results['both']}\")\n",
        "print(f\"Repositories with only projects enabled: {correlation_results['only_projects']}\")\n",
        "print(f\"Repositories with only wikis enabled: {correlation_results['only_wiki']}\")\n",
        "print(f\"Repositories with neither enabled: {correlation_results['neither']}\")\n",
        "print(f\"Total repositories analyzed: {correlation_results['total_repos']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJUYVBlvCiAM",
        "outputId": "cd098e90-a74a-4804-9a36-cc8f715656be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation Analysis of Projects and Wikis:\n",
            "Repositories with both projects and wikis: 56192\n",
            "Repositories with only projects enabled: 7907\n",
            "Repositories with only wikis enabled: 129\n",
            "Repositories with neither enabled: 2278\n",
            "Total repositories analyzed: 66506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "def load_boolean_data(file_path):\n",
        "    has_projects = []\n",
        "    has_wiki = []\n",
        "\n",
        "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "        csv_reader = csv.DictReader(file)\n",
        "        for row in csv_reader:\n",
        "            # Convert boolean values to 1 (True) and 0 (False)\n",
        "            projects = 1 if row[\"has_projects\"].strip().lower() == \"true\" else 0\n",
        "            wiki = 1 if row[\"has_wiki\"].strip().lower() == \"true\" else 0\n",
        "\n",
        "            has_projects.append(projects)\n",
        "            has_wiki.append(wiki)\n",
        "\n",
        "    return has_projects, has_wiki\n",
        "\n",
        "def calculate_correlation(has_projects, has_wiki):\n",
        "    correlation = np.corrcoef(has_projects, has_wiki)[0, 1]  # Get the correlation coefficient\n",
        "    return correlation\n",
        "\n",
        "# Main execution\n",
        "has_projects, has_wiki = load_boolean_data(\"repositories.csv\")\n",
        "correlation_coefficient = calculate_correlation(has_projects, has_wiki)\n",
        "\n",
        "print(\"Correlation coefficient between has_projects and has_wiki:\", correlation_coefficient)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuErj1xZCnz1",
        "outputId": "bd6c5b6e-c5ed-49cb-a428-8ef02ae872e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation coefficient between has_projects and has_wiki: 0.42684906204332856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from datetime import datetime, timedelta\n",
        "from collections import Counter\n",
        "\n",
        "def load_repository_data(file_path):\n",
        "    user_repo_count = Counter()\n",
        "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "        csv_reader = csv.DictReader(file)\n",
        "        for row in csv_reader:\n",
        "            created_at = datetime.strptime(row[\"created_at\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
        "            # Check if the created_at date is a weekend\n",
        "            if created_at.weekday() >= 5:  # 5=Saturday, 6=Sunday\n",
        "                user_repo_count[row[\"login\"]] += 1\n",
        "    return user_repo_count\n",
        "\n",
        "def get_top_users(user_repo_count, top_n=5):\n",
        "    # Get the top N users with the most repositories created on weekends\n",
        "    top_users = user_repo_count.most_common(top_n)\n",
        "    return [user[0] for user in top_users]\n",
        "\n",
        "# Main execution\n",
        "user_repo_count = load_repository_data(\"repositories.csv\")\n",
        "top_users = get_top_users(user_repo_count)\n",
        "\n",
        "print(\"Top 5 users who created the most repositories on weekends (UTC):\")\n",
        "print(\", \".join(top_users))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpL9fD8dGaWc",
        "outputId": "c148083b-a756-4c15-ffaa-1a7b14931e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 users who created the most repositories on weekends (UTC):\n",
            "azu, suzuki-shunsuke, yuiseki, xuwei-k, zchee\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "def load_bio_and_followers(file_path):\n",
        "    bio_lengths = []\n",
        "    followers_counts = []\n",
        "\n",
        "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "        csv_reader = csv.DictReader(file)\n",
        "        for row in csv_reader:\n",
        "            bio = row[\"bio\"].strip()\n",
        "            if bio:  # Only consider users with a bio\n",
        "                bio_length = len(bio.split())  # Split by whitespace to count words\n",
        "                bio_lengths.append(bio_length)\n",
        "                followers_counts.append(int(row[\"followers\"]))  # Convert followers to int\n",
        "\n",
        "    return bio_lengths, followers_counts\n",
        "\n",
        "def calculate_correlation(bio_lengths, followers_counts):\n",
        "    if len(bio_lengths) == 0 or len(followers_counts) == 0:\n",
        "        return None\n",
        "    correlation = np.corrcoef(bio_lengths, followers_counts)[0, 1]  # Get the correlation coefficient\n",
        "    return correlation\n",
        "\n",
        "# Main execution\n",
        "bio_lengths, followers_counts = load_bio_and_followers(\"users.csv\")\n",
        "correlation_coefficient = calculate_correlation(bio_lengths, followers_counts)\n",
        "\n",
        "print(\"Correlation coefficient between the length of bios and number of followers:\", correlation_coefficient)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwdJQiDSG3Ze",
        "outputId": "d0ce85ef-1d3f-4742-be2f-0246a43aa3f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation coefficient between the length of bios and number of followers: 0.10938474824006604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def analyze_hireable_emails(file_path):\n",
        "    hireable_with_email = 0\n",
        "    hireable_total = 0\n",
        "    not_hireable_with_email = 0\n",
        "    not_hireable_total = 0\n",
        "\n",
        "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "        csv_reader = csv.DictReader(file)\n",
        "        for row in csv_reader:\n",
        "            email = row[\"email\"].strip()\n",
        "            hireable = row[\"hireable\"].strip().lower() == \"true\"\n",
        "\n",
        "            if hireable:\n",
        "                hireable_total += 1\n",
        "                if email:  # Check if email is not empty\n",
        "                    hireable_with_email += 1\n",
        "            else:\n",
        "                not_hireable_total += 1\n",
        "                if email:  # Check if email is not empty\n",
        "                    not_hireable_with_email += 1\n",
        "\n",
        "    # Calculate fractions\n",
        "    hireable_fraction = hireable_with_email / hireable_total if hireable_total > 0 else 0\n",
        "    not_hireable_fraction = not_hireable_with_email / not_hireable_total if not_hireable_total > 0 else 0\n",
        "\n",
        "    # Calculate the difference\n",
        "    difference = round(hireable_fraction - not_hireable_fraction, 3)\n",
        "    return difference\n",
        "\n",
        "# Main execution\n",
        "email_difference = analyze_hireable_emails(\"users.csv\")\n",
        "\n",
        "print(\"Difference in email sharing between hireable and not hireable users:\", email_difference)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krIg3n1KLU6S",
        "outputId": "bf55568e-1b2d-4349-c01a-22c8185f22ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference in email sharing between hireable and not hireable users: 0.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('/content/users.csv')"
      ],
      "metadata": {
        "id": "b1azUXMwaeKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load the CSV file\n",
        "csv_file = '/content/users.csv'  # Ensure this path is correct\n",
        "\n",
        "# Load the CSV into a DataFrame\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# Check the first few rows and the data types of the DataFrame\n",
        "print(\"DataFrame Overview:\")\n",
        "print(df.head())\n",
        "print(\"\\nDataFrame Info:\")\n",
        "print(df.info())\n",
        "\n",
        "# Filter out users without bios\n",
        "df = df[df['bio'].notnull()]\n",
        "\n",
        "# Calculate the length of each bio in words\n",
        "df['bio_word_count'] = df['bio'].str.split().str.len()\n",
        "\n",
        "# Prepare the independent variable (X) and dependent variable (y)\n",
        "X = df['bio_word_count']\n",
        "y = df['followers']  # Adjust the column name as per your dataset\n",
        "\n",
        "# Add a constant to the independent variable (for the intercept)\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Get the slope (coefficient of the bio_word_count)\n",
        "slope = model.params['bio_word_count']\n",
        "\n",
        "# Print the regression slope rounded to three decimal places\n",
        "print(f\"\\nRegression slope of followers on bio word count: {slope:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuX-uRviTG4j",
        "outputId": "a2130f12-0d75-4d85-aa63-600db750bf9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame Overview:\n",
            "       login               name       company         location  \\\n",
            "0   tiangolo  Sebastián Ramírez           NaN  Berlin, Germany   \n",
            "1    schacon       Scott Chacon  GITBUTLERAPP  Berlin, Germany   \n",
            "2   rwieruch      Robin Wieruch           NaN    Berlin/Remote   \n",
            "3    shuding           Shu Ding        VERCEL           Berlin   \n",
            "4  android10     Fernando Cejas      PEPPR-IO  Berlin, Germany   \n",
            "\n",
            "                         email hireable  \\\n",
            "0           tiangolo@gmail.com     True   \n",
            "1            schacon@gmail.com      NaN   \n",
            "2                          NaN     True   \n",
            "3                    g@shud.in      NaN   \n",
            "4  android10@fernandocejas.com     True   \n",
            "\n",
            "                                                 bio  public_repos  followers  \\\n",
            "0  Creator of FastAPI, Typer, SQLModel, Asyncer, ...            73      26445   \n",
            "1                                                NaN           215      13757   \n",
            "2  React & Next.js • JavaScript & TypeScript • Fr...           151       8618   \n",
            "3  Be curious. Read widely. Try new things. — aar...           149       6756   \n",
            "4  Quantum Engineering at @Qruise-ai. Former Dire...            79       6716   \n",
            "\n",
            "   following            created_at  \n",
            "0          3  2012-01-12T22:37:04Z  \n",
            "1         26  2008-01-27T17:19:28Z  \n",
            "2         30  2012-10-03T15:11:48Z  \n",
            "3        345  2013-02-23T07:46:30Z  \n",
            "4         85  2012-01-20T21:35:31Z  \n",
            "\n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 601 entries, 0 to 600\n",
            "Data columns (total 11 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   login         601 non-null    object\n",
            " 1   name          591 non-null    object\n",
            " 2   company       360 non-null    object\n",
            " 3   location      601 non-null    object\n",
            " 4   email         326 non-null    object\n",
            " 5   hireable      230 non-null    object\n",
            " 6   bio           435 non-null    object\n",
            " 7   public_repos  601 non-null    int64 \n",
            " 8   followers     601 non-null    int64 \n",
            " 9   following     601 non-null    int64 \n",
            " 10  created_at    601 non-null    object\n",
            "dtypes: int64(3), object(8)\n",
            "memory usage: 51.8+ KB\n",
            "None\n",
            "\n",
            "Regression slope of followers on bio word count: 28.508\n"
          ]
        }
      ]
    }
  ]
}